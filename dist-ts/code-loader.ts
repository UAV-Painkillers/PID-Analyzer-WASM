export enum PYTHON_ANALYZER_CODE_NAMES {
  FULL = "old/PID-Analyzer.py",
  SPLIT_BBL = "split-bbl.py",
  ANALYZE_ONE_FLIGHT = "analyze-one-flight.py",
}

export async function loadCode(
  name: PYTHON_ANALYZER_CODE_NAMES
): Promise<string> {
  // TODO: update build pipeline to insert code here
  let code: string | undefined;
  switch (name) {
    case PYTHON_ANALYZER_CODE_NAMES.FULL: {
      code = `#!/usr/bin/env python\nimport logging\nimport os\nimport subprocess\nimport numpy as np\nfrom pandas import read_csv\nfrom scipy.interpolate import interp1d\nfrom scipy.ndimage.filters import gaussian_filter1d\nfrom scipy.optimize import minimize\nimport json\nfrom blackbox_decoder import decode as blackbox_decoder_decode # noqa\nfrom js_status import reportStatusToJs # noqa\n\n\n# ----------------------------------------------------------------------------------\n# "THE BEER-WARE LICENSE" (Revision 42):\n# <florian.melsheimer@gmx.de> wrote this file. As long as you retain this notice you\n# can do whatever you want with this stuff. If we meet some day, and you think\n# this stuff is worth it, you can buy me a beer in return. Florian Melsheimer\n# ----------------------------------------------------------------------------------\n\n\nVersion = 'PID-Analyzer 0.52'\n\nLOG_MIN_BYTES = 500000\n\nclass Trace:\n    framelen = 1.           # length of each single frame over which to compute response\n    resplen = 0.5           # length of respose window\n    cutfreq = 25.           # cutfreqency of what is considered as input\n    tuk_alpha = 1.0         # alpha of tukey window, if used\n    superpos = 16           # sub windowing (superpos windows in framelen)\n    low_threshold = 50      # treshold for 'looooow input rate'\n    threshold = 500.        # threshold for 'high input rate'\n    noise_framelen = 0.3    # window width for noise analysis\n    noise_superpos = 16     # subsampling for noise analysis windows\n\n    def to_json_object(self):\n        output = {\n            'name': self.name,\n            'gyro': self.gyro.tolist(),\n            'input': self.input.tolist(),\n            'time': self.time.tolist(),\n            'throttle': self.throttle.tolist(),\n            'avr_t': self.avr_t.tolist(),\n            'spec_sm': self.spec_sm.tolist(),\n            'thr_response': {\n                'hist2d_norm': {\n                    'histogram': self.thr_response['hist2d_norm'][0].tolist(),\n                    'bins': self.thr_response['hist2d_norm'][1].tolist()\n                }\n            },\n            'time_resp': self.time_resp.tolist(),\n            'resp_low': [\n                self.resp_low[0].tolist(),\n            ],\n            'high_mask': self.high_mask.tolist(),\n            'noise_gyro': {\n                'throt_hist_avr': self.noise_gyro['throt_hist_avr'].tolist(),\n                'throt_axis': self.noise_gyro['throt_axis'].tolist(),\n                'freq_axis': self.noise_gyro['freq_axis'].tolist(),\n                'hist2d_norm': self.noise_gyro['hist2d_norm'].tolist(),\n                'hist2d_sm': self.noise_gyro['hist2d_sm'].tolist(),\n                'hist2d': self.noise_gyro['hist2d'].tolist(),\n                'max': self.noise_gyro['max']\n            },\n            'noise_d': {\n                'throt_hist_avr': self.noise_d['throt_hist_avr'].tolist(),\n                'throt_axis': self.noise_d['throt_axis'].tolist(),\n                'freq_axis': self.noise_d['freq_axis'].tolist(),\n                'hist2d_norm': self.noise_d['hist2d_norm'].tolist(),\n                'hist2d_sm': self.noise_d['hist2d_sm'].tolist(),\n                'hist2d': self.noise_d['hist2d'].tolist(),\n                'max': self.noise_d['max']\n            },\n            'noise_debug': {\n                'throt_hist_avr': self.noise_debug['throt_hist_avr'].tolist(),\n                'throt_axis': self.noise_debug['throt_axis'].tolist(),\n                'freq_axis': self.noise_debug['freq_axis'].tolist(),\n                'hist2d_norm': self.noise_debug['hist2d_norm'].tolist(),\n                'hist2d_sm': self.noise_debug['hist2d_sm'].tolist(),\n                'hist2d': self.noise_debug['hist2d'].tolist(),\n                'max': self.noise_debug['max']\n            },\n            'filter_trans': self.filter_trans.tolist(),\n        }\n\n        if self.high_mask.sum()>0:\n            output['resp_high'] = self.resp_high[0].tolist()\n\n        return output\n\n    def __init__(self, data):\n        self.data = data\n        self.input = self.equalize(data['time'], self.pid_in(data['p_err'], data['gyro'], data['P']))[1]  # /20.\n        self.data.update({'input': self.pid_in(data['p_err'], data['gyro'], data['P'])})\n        self.equalize_data()\n\n        self.name = self.data['name']\n        self.time = self.data['time']\n        self.dt=self.time[0]-self.time[1]\n\n        self.input = self.data['input']\n        #enable this to generate artifical gyro trace with known system response\n        #self.data['gyro']=self.toy_out(self.input, delay=0.01, mode='normal')####\n\n        self.gyro = self.data['gyro']\n        self.throttle = self.data['throttle']\n        self.throt_hist, self.throt_scale = np.histogram(self.throttle, np.linspace(0, 100, 101, dtype=np.float64), density=True)\n\n        self.flen = self.stepcalc(self.time, Trace.framelen)        # array len corresponding to framelen in s\n        self.rlen = self.stepcalc(self.time, Trace.resplen)         # array len corresponding to resplen in s\n        self.time_resp = self.time[0:self.rlen]-self.time[0]\n\n        self.stacks = self.winstacker({'time':[],'input':[],'gyro':[], 'throttle':[]}, self.flen, Trace.superpos)                                  # [[time, input, output],]\n        self.window = np.hanning(self.flen)                                     #self.tukeywin(self.flen, self.tuk_alpha)\n        self.spec_sm, self.avr_t, self.avr_in, self.max_in, self.max_thr = self.stack_response(self.stacks, self.window)\n        self.low_mask, self.high_mask = self.low_high_mask(self.max_in, self.threshold)       #calcs masks for high and low inputs according to threshold\n        self.toolow_mask = self.low_high_mask(self.max_in, 20)[1]          #mask for ignoring noisy low input\n\n        self.resp_sm = self.weighted_mode_avr(self.spec_sm, self.toolow_mask, [-1.5,3.5], 1000)\n        self.resp_quality = -self.to_mask((np.abs(self.spec_sm -self.resp_sm[0]).mean(axis=1)).clip(0.5-1e-9,0.5))+1.\n        # masking by setting trottle of unwanted traces to neg\n        self.thr_response = self.hist2d(self.max_thr * (2. * (self.toolow_mask*self.resp_quality) - 1.), self.time_resp,\n                                        (self.spec_sm.transpose() * self.toolow_mask).transpose(), [101, self.rlen])\n\n        self.resp_low = self.weighted_mode_avr(self.spec_sm, self.low_mask*self.toolow_mask, [-1.5,3.5], 1000)\n        if self.high_mask.sum()>0:\n            self.resp_high = self.weighted_mode_avr(self.spec_sm, self.high_mask*self.toolow_mask, [-1.5,3.5], 1000)\n\n        self.noise_winlen = self.stepcalc(self.time, Trace.noise_framelen)\n        self.noise_stack = self.winstacker({'time':[], 'gyro':[], 'throttle':[], 'd_err':[], 'debug':[]},\n                                           self.noise_winlen, Trace.noise_superpos)\n        self.noise_win = np.hanning(self.noise_winlen)\n\n        self.noise_gyro = self.stackspectrum(self.noise_stack['time'],self.noise_stack['throttle'],self.noise_stack['gyro'], self.noise_win)\n        self.noise_d = self.stackspectrum(self.noise_stack['time'], self.noise_stack['throttle'], self.noise_stack['d_err'], self.noise_win)\n        self.noise_debug = self.stackspectrum(self.noise_stack['time'], self.noise_stack['throttle'], self.noise_stack['debug'], self.noise_win)\n        if self.noise_debug['hist2d'].sum()>0:\n            ## mask 0 entries\n            thr_mask = self.noise_gyro['throt_hist_avr'].clip(0,1)\n            self.filter_trans = np.average(self.noise_gyro['hist2d'], axis=1, weights=thr_mask)/\\n                                np.average(self.noise_debug['hist2d'], axis=1, weights=thr_mask)\n        else:\n            self.filter_trans = self.noise_gyro['hist2d'].mean(axis=1)*0.\n\n    @staticmethod\n    def low_high_mask(signal, threshold):\n        low = np.copy(signal)\n\n        low[low <=threshold] = 1.\n        low[low > threshold] = 0.\n        high = -low+1.\n\n        if high.sum() < 10:     # ignore high pinput that is too short\n            high *= 0.\n\n        return low, high\n\n    def to_mask(self, clipped):\n        clipped-=clipped.min()\n        clipped/=clipped.max()\n        return clipped\n\n    def pid_in(self, pval, gyro, pidp):\n        pidin = gyro + pval / (0.032029 * pidp)       # 0.032029 is P scaling factor from betaflight\n        return pidin\n\n    def rate_curve(self, rcin, inmax=500., outmax=800., rate=160.):\n        ### an estimated rate curve. not used.\n        expoin = (np.exp((rcin - inmax) / rate) - np.exp((-rcin - inmax) / rate)) * outmax\n        return expoin\n\n    def calc_delay(self, time, trace1, trace2):\n        ### minimizes trace1-trace2 by shifting trace1\n        tf1 = interp1d(time[2000:-2000], trace1[2000:-2000], fill_value=0., bounds_error=False)\n        tf2 = interp1d(time[2000:-2000], trace2[2000:-2000], fill_value=0., bounds_error=False)\n        fun = lambda x: ((tf1(time - x*0.5) - tf2(time+ x*0.5)) ** 2).mean()\n        shift = minimize(fun, np.array([0.01])).x[0]\n        steps = np.round(shift / (time[1] - time[0]))\n        return {'time':shift, 'steps':int(steps)}\n\n    def tukeywin(self, len, alpha=0.5):\n        ### makes tukey widow for envelopig\n        M = len\n        n = np.arange(M - 1.)  #\n        if alpha <= 0:\n            return np.ones(M)  # rectangular window\n        elif alpha >= 1:\n            return np.hanning(M)\n\n        # Normal case\n        x = np.linspace(0, 1, M, dtype=np.float64)\n        w = np.ones(x.shape)\n\n        # first condition 0 <= x < alpha/2\n        first_condition = x < alpha / 2\n        w[first_condition] = 0.5 * (1 + np.cos(2 * np.pi / alpha * (x[first_condition] - alpha / 2)))\n\n        # second condition already taken care of\n\n        # third condition 1 - alpha / 2 <= x <= 1\n        third_condition = x >= (1 - alpha / 2)\n        w[third_condition] = 0.5 * (1 + np.cos(2 * np.pi / alpha * (x[third_condition] - 1 + alpha / 2)))\n\n        return w\n\n    def toy_out(self, inp, delay=0.01, length=0.01, noise=5., mode='normal', sinfreq=100.):\n        # generates artificial output for benchmarking\n        freq= 1./(self.time[1]-self.time[0])\n        toyresp = np.zeros(int((delay+length)*freq))\n        toyresp[int((delay)*freq):]=1.\n        toyresp/=toyresp.sum()\n        toyout = np.convolve(inp, toyresp, mode='full')[:len(inp)]#*0.9\n        if mode=='normal':\n            noise_sig = (np.random.random_sample(len(toyout))-0.5)*noise\n        elif mode=='sin':\n            noise_sig = (np.sin(2.*np.pi*self.time*sinfreq)) * noise\n        else:\n            noise_sig=0.\n        return toyout+noise_sig\n\n    def equalize(self, time, data):\n        ### equalizes time scale\n        data_f = interp1d(time, data)\n        newtime = np.linspace(time[0], time[-1], len(time), dtype=np.float64)\n        return newtime, data_f(newtime)\n\n    def equalize_data(self):\n        ### equalizes full dict of data\n        time = self.data['time']\n        newtime = np.linspace(time[0], time[-1], len(time), dtype=np.float64)\n        for key in self.data:\n              if isinstance(self.data[key],np.ndarray):\n                  if len(self.data[key])==len(time):\n                      self.data[key]= interp1d(time, self.data[key])(newtime)\n        self.data['time']=newtime\n\n    def stepcalc(self, time, duration):\n        ### calculates frequency and resulting windowlength\n        tstep = (time[1]-time[0])\n        freq = 1./tstep\n        arr_len = duration * freq\n        return int(arr_len)\n\n    def winstacker(self, stackdict, flen, superpos):\n        ### makes stack of windows for deconvolution\n        tlen = len(self.data['time'])\n        shift = int(flen/superpos)\n        wins = int(tlen/shift)-superpos\n        for i in np.arange(wins):\n            for key in stackdict.keys():\n                stackdict[key].append(self.data[key][i * shift:i * shift + flen])\n        for k in stackdict.keys():\n            #print 'key',k\n            #print stackdict[k]\n            stackdict[k]=np.array(stackdict[k], dtype=np.float64)\n        return stackdict\n\n    def wiener_deconvolution(self, input, output, cutfreq):      # input/output are two-dimensional\n        pad = 1024 - (len(input[0]) % 1024)                     # padding to power of 2, increases transform speed\n        input = np.pad(input, [[0,0],[0,pad]], mode='constant')\n        output = np.pad(output, [[0, 0], [0, pad]], mode='constant')\n        H = np.fft.fft(input, axis=-1)\n        G = np.fft.fft(output,axis=-1)\n        freq = np.abs(np.fft.fftfreq(len(input[0]), self.dt))\n        sn = self.to_mask(np.clip(np.abs(freq), cutfreq-1e-9, cutfreq))\n        len_lpf=np.sum(np.ones_like(sn)-sn)\n        sn=self.to_mask(gaussian_filter1d(sn,len_lpf/6.))\n        sn= 10.*(-sn+1.+1e-9)       # +1e-9 to prohibit 0/0 situations\n        Hcon = np.conj(H)\n        deconvolved_sm = np.real(np.fft.ifft(G * Hcon / (H * Hcon + 1./sn),axis=-1))\n        return deconvolved_sm\n\n    def stack_response(self, stacks, window):\n        inp = stacks['input'] * window\n        outp = stacks['gyro'] * window\n        thr = stacks['throttle'] * window\n\n        deconvolved_sm = self.wiener_deconvolution(inp, outp, self.cutfreq)[:, :self.rlen]\n        delta_resp = deconvolved_sm.cumsum(axis=1)\n\n        max_thr = np.abs(np.abs(thr)).max(axis=1)\n        avr_in = np.abs(np.abs(inp)).mean(axis=1)\n        max_in = np.max(np.abs(inp), axis=1)\n        avr_t = stacks['time'].mean(axis=1)\n\n        return delta_resp, avr_t, avr_in, max_in, max_thr\n\n    def spectrum(self, time, traces):\n        ### fouriertransform for noise analysis. returns frequencies and spectrum.\n        pad = 1024 - (len(traces[0]) % 1024)  # padding to power of 2, increases transform speed\n        traces = np.pad(traces, [[0, 0], [0, pad]], mode='constant')\n        trspec = np.fft.rfft(traces, axis=-1, norm='ortho')\n        trfreq = np.fft.rfftfreq(len(traces[0]), time[1] - time[0])\n        return trfreq, trspec\n\n    def stackfilter(self, time, trace_ref, trace_filt, window):\n        ### calculates filter transmission and phaseshift from stack of windows. Not in use, maybe later.\n        # slicing off last 2s to get rid of landing\n        #maybe pass throttle for further analysis...\n        filt = trace_filt[:-int(Trace.noise_superpos * 2. / Trace.noise_framelen), :] * window\n        ref = trace_ref[:-int(Trace.noise_superpos * 2. / Trace.noise_framelen), :] * window\n        time = time[:-int(Trace.noise_superpos * 2. / Trace.noise_framelen), :]\n\n        full_freq_f, full_spec_f = self.spectrum(self.data['time'], [self.data['gyro']])\n        full_freq_r, full_spec_r = self.spectrum(self.data['time'], [self.data['debug']])\n\n        f_amp_freq, f_amp_hist =np.histogram(full_freq_f, weights=np.abs(full_spec_f.real).flatten(), bins=int(full_freq_f[-1]))\n        r_amp_freq, r_amp_hist = np.histogram(full_freq_r, weights=np.abs(full_spec_r.real).flatten(), bins=int(full_freq_r[-1]))\n\n    def hist2d(self, x, y, weights, bins):   #bins[nx,ny]\n        ### generates a 2d hist from input 1d axis for x,y. repeats them to match shape of weights X*Y (data points)\n        ### x will be 0-100%\n        freqs = np.repeat(np.array([y], dtype=np.float64), len(x), axis=0)\n        throts = np.repeat(np.array([x], dtype=np.float64), len(y), axis=0).transpose()\n        throt_hist_avr, throt_scale_avr = np.histogram(x, 101, [0, 100])\n\n        hist2d = np.histogram2d(throts.flatten(), freqs.flatten(),\n                                range=[[0, 100], [y[0], y[-1]]],\n                                bins=bins, weights=weights.flatten(), density=False)[0].transpose()\n\n        hist2d = np.array(abs(hist2d), dtype=np.float64)\n        hist2d_norm = np.copy(hist2d)\n        hist2d_norm /=  (throt_hist_avr + 1e-9)\n\n        return {'hist2d_norm':hist2d_norm, 'hist2d':hist2d, 'throt_hist':throt_hist_avr,'throt_scale':throt_scale_avr}\n\n    def stackspectrum(self, time, throttle, trace, window):\n        ### calculates spectrogram from stack of windows against throttle.\n        # slicing off last 2s to get rid of landing\n        gyro = trace[:-int(Trace.noise_superpos*2./Trace.noise_framelen),:] * window\n        thr = throttle[:-int(Trace.noise_superpos*2./Trace.noise_framelen),:] * window\n        time = time[:-int(Trace.noise_superpos*2./Trace.noise_framelen),:]\n\n        freq, spec = self.spectrum(time[0], gyro)\n\n        weights = abs(spec.real)\n        avr_thr = np.abs(thr).max(axis=1)\n\n        hist2d=self.hist2d(avr_thr, freq,weights,[101,int(len(freq)/4)])\n\n        filt_width = 3  # width of gaussian smoothing for hist data\n        hist2d_sm = gaussian_filter1d(hist2d['hist2d_norm'], filt_width, axis=1, mode='constant')\n\n        # get max value in histogram >100hz\n        thresh = 100.\n        mask = self.to_mask(freq[:-1:4].clip(thresh-1e-9,thresh))\n        maxval = np.max(hist2d_sm.transpose()*mask)\n\n        return {'throt_hist_avr':hist2d['throt_hist'],'throt_axis':hist2d['throt_scale'],'freq_axis':freq[::4],\n                'hist2d_norm':hist2d['hist2d_norm'], 'hist2d_sm':hist2d_sm, 'hist2d':hist2d['hist2d'], 'max':maxval}\n\n    def weighted_mode_avr(self, values, weights, vertrange, vertbins):\n        ### finds the most common trace and std\n        threshold = 0.5  # threshold for std calculation\n        filt_width = 7  # width of gaussian smoothing for hist data\n\n        resp_y = np.linspace(vertrange[0], vertrange[-1], vertbins, dtype=np.float64)\n        times = np.repeat(np.array([self.time_resp],dtype=np.float64), len(values), axis=0)\n        weights = np.repeat(weights, len(values[0]))\n\n        hist2d = np.histogram2d(times.flatten(), values.flatten(),\n                                range=[[self.time_resp[0], self.time_resp[-1]], vertrange],\n                                bins=[len(times[0]), vertbins], weights=weights.flatten())[0].transpose()\n        ### shift outer edges by +-1e-5 (10us) bacause of dtype32. Otherwise different precisions lead to artefacting.\n        ### solution to this --> somethings strage here. In outer most edges some bins are doubled, some are empty.\n        ### Hence sometimes produces "divide by 0 error" in "/=" operation.\n\n        if hist2d.sum():\n            hist2d_sm = gaussian_filter1d(hist2d, filt_width, axis=0, mode='constant')\n            hist2d_sm /= np.max(hist2d_sm, 0)\n\n\n            pixelpos = np.repeat(resp_y.reshape(len(resp_y), 1), len(times[0]), axis=1)\n            avr = np.average(pixelpos, 0, weights=hist2d_sm * hist2d_sm)\n        else:\n            hist2d_sm = hist2d\n            avr = np.zeros_like(self.time_resp)\n        # only used for monochrome error width\n        hist2d[hist2d <= threshold] = 0.\n        hist2d[hist2d > threshold] = 0.5 / (vertbins / (vertrange[-1] - vertrange[0]))\n\n        std = np.sum(hist2d, 0)\n\n        return avr, std, [self.time_resp, resp_y, hist2d_sm]\n\n    ### calculates weighted avverage and resulting errors\n    def weighted_avg_and_std(self, values, weights):\n        average = np.average(values, axis=0, weights=weights)\n        variance = np.average((values - average) ** 2, axis=0, weights=weights)\n        return (average, np.sqrt(variance))\n\nclass CSV_log:\n    def __init__(self, fpath, name, headdict, noise_bounds):\n        self.file = fpath\n        self.name = name\n        self.headdict = headdict\n\n    async def asyncInit(self):\n        await reportStatusToJs("READING_DECODED_SUB_BBL_START")\n        self.data = self.readcsv(self.file)\n        await reportStatusToJs("READING_DECODED_SUB_BBL_COMPLETE")\n\n        self.traces = self.find_traces(self.data)\n        await reportStatusToJs("RUNNING_PID_ANALYSIS_ON_SUB_BBL_START")\n        self.roll, self.pitch, self.yaw = self.__analyze()\n        await reportStatusToJs("RUNNING_PID_ANALYSIS_ON_SUB_BBL_COMPLETE")\n\n        await reportStatusToJs("SAVING_PID_ANALYSIS_RESULTS_FROM_SUB_BBL_START")\n        fpath = self.file\n        jsonFileName = fpath.replace('.csv', '.json')\n        combinedJsonOutput = {\n            'roll': self.roll.to_json_object(),\n            'pitch': self.pitch.to_json_object(),\n            'yaw': self.yaw.to_json_object(),\n            'headdict': self.headdict\n        }\n        with open(jsonFileName, 'w') as jsonFile:\n            jsonFile.write(json.dumps(combinedJsonOutput, indent=4, sort_keys=True))\n        jsonFile.close()\n        await reportStatusToJs("SAVING_PID_ANALYSIS_RESULTS_FROM_SUB_BBL_COMPLETE")\n\n    def __analyze(self):\n        analyzed = []\n        for t in self.traces:\n            logging.info(t['name'] + '...   ')\n            analyzed.append(Trace(t))\n        return analyzed\n\n    def readcsv(self, fpath):\n        logging.info('Reading: Log '+str(self.headdict['logNum']))\n        datdic = {}\n        ### keycheck for 'usecols' only reads usefull traces, uncommend if needed\n        wanted =  ['time (us)',\n                   'rcCommand[0]', 'rcCommand[1]', 'rcCommand[2]', 'rcCommand[3]',\n                   'axisP[0]','axisP[1]','axisP[2]',\n                   'axisI[0]', 'axisI[1]', 'axisI[2]',\n                   'axisD[0]', 'axisD[1]','axisD[2]',\n                   'gyroADC[0]', 'gyroADC[1]', 'gyroADC[2]',\n                   'gyroData[0]', 'gyroData[1]', 'gyroData[2]',\n                   'ugyroADC[0]', 'ugyroADC[1]', 'ugyroADC[2]',\n                   #'accSmooth[0]','accSmooth[1]', 'accSmooth[2]',\n                   'debug[0]', 'debug[1]', 'debug[2]','debug[3]',\n                   #'motor[0]', 'motor[1]', 'motor[2]', 'motor[3]',\n                   #'energyCumulative (mAh)','vbatLatest (V)', 'amperageLatest (A)'\n                   ]\n        data = read_csv(fpath, header=0, skipinitialspace=1, usecols=lambda k: k in wanted, dtype=np.float64)\n        datdic.update({'time_us': data['time (us)'].values * 1e-6})\n        datdic.update({'throttle': data['rcCommand[3]'].values})\n\n        for i in ['0', '1', '2']:\n            datdic.update({'rcCommand' + i: data['rcCommand['+i+']'].values})\n            #datdic.update({'PID loop in' + i: data['axisP[' + i + ']'].values})\n            try:\n                datdic.update({'debug' + i: data['debug[' + i + ']'].values})\n            except:\n                logging.warning('No debug['+str(i)+'] trace found!')\n                datdic.update({'debug' + i: np.zeros_like(data['rcCommand[' + i + ']'].values)})\n\n            # get P trace (including case of missing trace)\n            try:\n                datdic.update({'PID loop in' + i: data['axisP[' + i + ']'].values})\n            except:\n                logging.warning('No P['+str(i)+'] trace found!')\n                datdic.update({'PID loop in' + i: np.zeros_like(data['rcCommand[' + i + ']'].values)})\n\n            try:\n                datdic.update({'d_err'+i: data['axisD[' + i+']'].values})\n            except:\n                logging.warning('No D['+str(i)+'] trace found!')\n                datdic.update({'d_err' + i: np.zeros_like(data['rcCommand[' + i + ']'].values)})\n\n            try:\n                datdic.update({'I_term'+i: data['axisI[' + i+']'].values})\n            except:\n                if i<2:\n                    logging.warning('No I['+str(i)+'] trace found!')\n                datdic.update({'I_term' + i: np.zeros_like(data['rcCommand[' + i + ']'].values)})\n\n            datdic.update({'PID sum' + i: datdic['PID loop in'+i]+datdic['I_term'+i]+datdic['d_err'+i]})\n            \n            if 'gyroADC[0]' in data.keys():\n                datdic.update({'gyroData' + i: data['gyroADC[' + i+']'].values})\n            elif 'gyroData[0]' in data.keys():\n                datdic.update({'gyroData' + i: data['gyroData[' + i+']'].values})\n            elif 'ugyroADC[0]' in data.keys():\n                datdic.update({'gyroData' + i: data['ugyroADC[' + i+']'].values})\n            else:\n                logging.warning('No gyro trace found!')\n        return datdic\n\n\n    def find_traces(self, dat):\n        time = self.data['time_us']\n        throttle = dat['throttle']\n\n        throt = ((throttle - 1000.) / (float(self.headdict['maxThrottle']) - 1000.)) * 100.\n\n        traces = [{'name':'roll'},{'name':'pitch'},{'name':'yaw'}]\n\n        for i, dic in enumerate(traces):\n            dic.update({'time':time})\n            dic.update({'p_err':dat['PID loop in'+str(i)]})\n            dic.update({'rcinput': dat['rcCommand' + str(i)]})\n            dic.update({'gyro':dat['gyroData'+str(i)]})\n            dic.update({'PIDsum':dat['PID sum'+str(i)]})\n            dic.update({'d_err': dat['d_err' + str(i)]})\n            dic.update({'debug': dat['debug' + str(i)]})\n            if 'KISS' in self.headdict['fwType']:\n                dic.update({'P': 1.})\n                self.headdict.update({'tpa_percent': 0.})\n            elif 'Raceflight' in self.headdict['fwType']:\n                dic.update({'P': 1.})\n                self.headdict.update({'tpa_percent': 0.})\n\n            else:\n                dic.update({'P':float((self.headdict[dic['name']+'PID']).split(',')[0])})\n                self.headdict.update({'tpa_percent': (float(self.headdict['tpa_breakpoint']) - 1000.) / 10.})\n\n            dic.update({'throttle':throt})\n\n        return traces\n\n\nclass BB_log:\n    def __init__(self, log_file_path, noise_bounds):\n        self.name = "tmp"\n        self.log_file_path = log_file_path\n        self.tmp_dir = os.path.join(os.path.dirname(self.log_file_path), self.name)\n        if not os.path.isdir(self.tmp_dir):\n            os.makedirs(self.tmp_dir)\n        self.noise_bounds=noise_bounds\n\n    async def asyncInit(self):\n        await reportStatusToJs("PROCESSING_MAIN_BBL")\n\n        self.loglist = await self.decode(self.log_file_path)\n        self.heads = await self.beheader(self.loglist)\n        self.figs = await self._csv_iter(self.heads)\n        self.deletejunk(self.loglist)\n\n    async def decode(self, fpath):\n        """Splits out one BBL per recorded session and converts each to CSV."""\n        with open(fpath, 'rb') as binary_log_view:\n            content = binary_log_view.read()\n\n        # The first line of the overall BBL file re-appears at the beginning\n        # of each recorded session.\n        try:\n          first_newline_index = content.index(str('\n').encode('utf8'))\n        except ValueError as e:\n            raise ValueError(\n                'No newline in %dB of log data from %r.'\n                % (len(content), fpath),\n                e)\n        firstline = content[:first_newline_index + 1]\n\n        split = content.split(firstline)\n        bbl_sessions = []\n        for i in range(len(split)):\n            path_root, path_ext = os.path.splitext(os.path.basename(fpath))\n            temp_path = os.path.join(\n                self.tmp_dir, '%s_temp%d%s' % (path_root, i, path_ext))\n            with open(temp_path, 'wb') as newfile:\n                newfile.write(firstline+split[i])\n            bbl_sessions.append(temp_path)\n\n        await reportStatusToJs("DECODING_SUB_BBLS", len(bbl_sessions))\n\n        loglist = []\n        for bbl_session in bbl_sessions:\n            size_bytes = os.path.getsize(os.path.join(self.tmp_dir, bbl_session))\n            if size_bytes > LOG_MIN_BYTES:\n                try:\n                    await reportStatusToJs("DECODE_SUB_BBL_START")\n                    await blackbox_decoder_decode(bbl_session)\n                    await reportStatusToJs("DECODE_SUB_BBL_COMPLETE")\n                    loglist.append(bbl_session)\n                except:\n                    logging.error(\n                        'Error in Blackbox_decode of %r' % bbl_session, exc_info=True)\n            else:\n                await reportStatusToJs("DECODE_SUB_BBL_SKIPPED")\n                os.remove(bbl_session)\n\n        return loglist\n\n    async def beheader(self, loglist):\n        heads = []\n        for i, bblog in enumerate(loglist):\n            await reportStatusToJs("READING_HEADERS_FROM_SUB_BBL_START")\n            log = open(os.path.join(self.tmp_dir, bblog), 'rb')\n            lines = log.readlines()\n            ### in case info is not provided by log, empty str is printed in plot\n            headsdict = {'tempFile'     :'',\n                         'dynThrottle' :'',\n                         'craftName'   :'',\n                         'fwType': '',\n                         'version'     :'',\n                         'date'        :'',\n                         'rcRate'      :'',\n                         'rcExpo'       :'',\n                         'rcYawExpo'    :'',\n                         'rcYawRate'   :'',\n                         'rates'        :'',\n                         'rollPID'     :'',\n                         'pitchPID'    :'',\n                         'yawPID'      :'',\n                         'deadBand'    :'',\n                         'yawDeadBand' :'',\n                         'logNum'       :'',\n                         'tpa_breakpoint':'0',\n                         'minThrottle':'',\n                         'maxThrottle': '',\n                         'tpa_percent':'',\n                         'dTermSetPoint':'',\n                         'vbatComp':'',\n                         'gyro_lpf':'',\n                         'gyro_lowpass_type':'',\n                         'gyro_lowpass_hz':'',\n                         'gyro_notch_hz':'',\n                         'gyro_notch_cutoff':'',\n                         'dterm_filter_type':'',\n                         'dterm_lpf_hz':'',\n                         'yaw_lpf_hz':'',\n                         'dterm_notch_hz':'',\n                         'dterm_notch_cutoff':'',\n                         'debug_mode':''\n                         }\n            ### different versions of fw have different names for the same thing.\n            translate_dic={'dynThrPID:':'dynThrottle',\n                         'Craft name:':'craftName',\n                         'Firmware type:':'fwType',\n                         'Firmware revision:':'version',\n                         'Firmware date:':'fwDate',\n                         'rcRate:':'rcRate', 'rc_rate:':'rcRate',\n                         'rcExpo:':'rcExpo', 'rc_expo:':'rcExpo',\n                         'rcYawExpo:':'rcYawExpo', 'rc_expo_yaw:':'rcYawExpo',\n                         'rcYawRate:':'rcYawRate', 'rc_rate_yaw:':'rcYawRate',\n                         'rates:':'rates',\n                         'rollPID:':'rollPID',\n                         'pitchPID:':'pitchPID',\n                         'yawPID:':'yawPID',\n                         ' deadband:':'deadBand',\n                         'yaw_deadband:':'yawDeadBand',\n                         'tpa_breakpoint:':'tpa_breakpoint',\n                         'minthrottle:':'minThrottle',\n                         'maxthrottle:':'maxThrottle',\n                         'dtermSetpointWeight:':'dTermSetPoint','dterm_setpoint_weight:':'dTermSetPoint',\n                         'vbat_pid_compensation:':'vbatComp','vbat_pid_gain:':'vbatComp',\n                         'gyro_lpf:':'gyro_lpf',\n                         'gyro_lowpass_type:':'gyro_lowpass_type',\n                         'gyro_lowpass_hz:':'gyro_lowpass_hz','gyro_lpf_hz:':'gyro_lowpass_hz',\n                         'gyro_notch_hz:':'gyro_notch_hz',\n                         'gyro_notch_cutoff:':'gyro_notch_cutoff',\n                         'dterm_filter_type:':'dterm_filter_type',\n                         'dterm_lpf_hz:':'dterm_lpf_hz',\n                         'yaw_lpf_hz:':'yaw_lpf_hz',\n                         'dterm_notch_hz:':'dterm_notch_hz',\n                         'dterm_notch_cutoff:':'dterm_notch_cutoff',\n                         'debug_mode:':'debug_mode'\n                         }\n\n            headsdict['tempFile'] = bblog\n            headsdict['logNum'] = str(i)\n            ### check for known keys and translate to useful ones.\n            for raw_line in lines:\n                l = raw_line.decode('latin-1')\n                for k in translate_dic.keys():\n                    if k in l:\n                        val =l.split(':')[-1]\n                        headsdict.update({translate_dic[k]:val[:-1]})\n\n            heads.append(headsdict)\n            await reportStatusToJs("READING_HEADERS_FROM_SUB_BBL_COMPLETE")\n        return heads\n\n    async def _csv_iter(self, heads):\n        figs = []\n        for h in heads:\n            log = CSV_log(h['tempFile'][:-3]+'01.csv', self.name, h, self.noise_bounds)\n            await log.asyncInit()\n        return figs\n\n    def deletejunk(self, loglist):\n        for l in loglist:\n            os.remove(l)\n            os.remove(l[:-3]+'01.csv')\n            try:\n                os.remove(l[:-3]+'01.event')\n            except:\n                logging.warning('No .event file of '+l+' found.')\n        return\n\n\nasync def run_analysis(log_file_path, noise_bounds):\n    bbLog = BB_log(log_file_path, noise_bounds)\n    await bbLog.asyncInit()\n    await reportStatusToJs("PID_ANALYSIS_COMPLETE")\n\n\ndef strip_quotes(filepath):\n    """Strips single or double quotes and extra whitespace from a string."""\n    return filepath.strip().strip("'").strip('"')\n\n\ndef clean_path(path):\n    return os.path.abspath(os.path.expanduser(strip_quotes(path)))\n\nlogging.basicConfig(\n    format='%(levelname)s %(asctime)s %(filename)s:%(lineno)s: %(message)s',\n    level=logging.INFO)\n\nlog_path = "/logs/flightlog.bbl"\nnoise_bounds = [[1.,10.1],[1.,100.],[1.,100.],[0.,4.]]\n\nawait run_analysis(clean_path(log_path), noise_bounds)`.trim();
      break;
    }
    case PYTHON_ANALYZER_CODE_NAMES.SPLIT_BBL: {
      code = `import os\nfrom js_status import reportStatusToJs # noqa\nfrom blackbox_decoder import decode as blackbox_decoder_decode # noqa\nimport json\n\nLOG_MIN_BYTES = 500000\n\nasync def split_bbl(bbl_path, out_path):\n    """\n    Split the BBL file into multiple sub-files based on recorded sessions.\n\n    Args:\n        bbl_path (str): The path to the BBL file.\n        out_path (str): The output directory where the sub-files will be saved.\n\n    Raises:\n        ValueError: If there is no newline character in the BBL file.\n\n    Returns:\n        None\n    """\n\n    await reportStatusToJs("SPLITTING BBL")\n    with open(bbl_path, 'rb') as binary_log_view:\n        content = binary_log_view.read()\n\n    # The first line of the overall BBL file re-appears at the beginning\n    # of each recorded session.\n    try:\n        first_newline_index = content.index(str('\n').encode('utf8'))\n    except ValueError as e:\n        raise ValueError('No newline in') from e\n\n    firstline = content[:first_newline_index + 1]\n\n    raw_logs = content.split(firstline)\n\n    sub_bbl_file_names = []\n    for log_index, raw_log in enumerate(raw_logs):\n        _, path_ext = os.path.splitext(os.path.basename(bbl_path))\n        sub_bbl_path = os.path.join(out_path, f"{log_index}{path_ext}")\n\n        with open(sub_bbl_path, 'wb') as sub_bbl:\n            sub_bbl.write(firstline + raw_log)\n        sub_bbl_file_names.append(sub_bbl_path)\n\n    await reportStatusToJs("BBLS SPLITTED", len(sub_bbl_file_names))\n\n    return sub_bbl_file_names\n\nasync def get_log_header(sub_bbl_filename_list):\n    """\n    Reads the headers from a list of sub BBL files and returns a list of dictionaries containing the header information.\n\n    Parameters:\n    - sub_bbl_filename_list (list): A list of sub BBL file names.\n\n    Returns:\n    - all_header (list): A list of dictionaries, where each dictionary contains the header information for a sub BBL file.\n\n    """\n    await reportStatusToJs("READING_HEADERS_START", len(sub_bbl_filename_list))\n\n    all_header = []\n    for sub_bbl_index, sub_bbl_filename in enumerate(sub_bbl_filename_list):\n        await reportStatusToJs("READING_HEADERS_FROM_SUB_BBL_START", sub_bbl_index)\n\n        sub_bbl_file = open(sub_bbl_filename, 'rb')\n        lines = sub_bbl_file.readlines()\n\n        ### in case info is not provided by log, empty str is printed in plot\n        header = {\n            'tempFile'          :'',\n            'dynThrottle'       :'',\n            'craftName'         :'',\n            'fwType'            :'',\n            'version'           :'',\n            'date'              :'',\n            'rcRate'            :'',\n            'rcExpo'            :'',\n            'rcYawExpo'         :'',\n            'rcYawRate'         :'',\n            'rates'             :'',\n            'rollPID'           :'',\n            'pitchPID'          :'',\n            'yawPID'            :'',\n            'deadBand'          :'',\n            'yawDeadBand'       :'',\n            'logNum'            :'',\n            'tpa_breakpoint'    :'0',\n            'minThrottle'       :'',\n            'maxThrottle'       :'',\n            'tpa_percent'       :'',\n            'dTermSetPoint'     :'',\n            'vbatComp'          :'',\n            'gyro_lpf'          :'',\n            'gyro_lowpass_type' :'',\n            'gyro_lowpass_hz'   :'',\n            'gyro_notch_hz'     :'',\n            'gyro_notch_cutoff' :'',\n            'dterm_filter_type' :'',\n            'dterm_lpf_hz'      :'',\n            'yaw_lpf_hz'        :'',\n            'dterm_notch_hz'    :'',\n            'dterm_notch_cutoff':'',\n            'debug_mode'        :''\n        }\n\n        ### different versions of fw have different names for the same thing.\n        translate_dic={\n            'dynThrPID:'            :'dynThrottle',\n            'Craft name:'           :'craftName',\n            'Firmware type:'        :'fwType',\n            'Firmware revision:'    :'version',\n            'Firmware date:'        :'fwDate',\n            'rcRate:'               :'rcRate',\n            'rc_rate:'              :'rcRate',\n            'rcExpo:'               :'rcExpo',\n            'rc_expo:'              :'rcExpo',\n            'rcYawExpo:'            :'rcYawExpo',\n            'rc_expo_yaw:'          :'rcYawExpo',\n            'rcYawRate:'            :'rcYawRate',\n            'rc_rate_yaw:'          :'rcYawRate',\n            'rates:'                :'rates',\n            'rollPID:'              :'rollPID',\n            'pitchPID:'             :'pitchPID',\n            'yawPID:'               :'yawPID',\n            ' deadband:'            :'deadBand',\n            'yaw_deadband:'         :'yawDeadBand',\n            'tpa_breakpoint:'       :'tpa_breakpoint',\n            'minthrottle:'          :'minThrottle',\n            'maxthrottle:'          :'maxThrottle',\n            'dtermSetpointWeight:'  :'dTermSetPoint',\n            'dterm_setpoint_weight:':'dTermSetPoint',\n            'vbat_pid_compensation:':'vbatComp',\n            'vbat_pid_gain:'        :'vbatComp',\n            'gyro_lpf:'             :'gyro_lpf',\n            'gyro_lowpass_type:'    :'gyro_lowpass_type',\n            'gyro_lowpass_hz:'      :'gyro_lowpass_hz',\n            'gyro_lpf_hz:'          :'gyro_lowpass_hz',\n            'gyro_notch_hz:'        :'gyro_notch_hz',\n            'gyro_notch_cutoff:'    :'gyro_notch_cutoff',\n            'dterm_filter_type:'    :'dterm_filter_type',\n            'dterm_lpf_hz:'         :'dterm_lpf_hz',\n            'yaw_lpf_hz:'           :'yaw_lpf_hz',\n            'dterm_notch_hz:'       :'dterm_notch_hz',\n            'dterm_notch_cutoff:'   :'dterm_notch_cutoff',\n            'debug_mode:'           :'debug_mode'\n        }\n\n        header['tempFile'] = sub_bbl_filename\n        header['logNum'] = str(sub_bbl_index)\n        ### check for known keys and translate to useful ones.\n        for raw_line in lines:\n            decoded_line = raw_line.decode('latin-1')\n            for translation_key, translation_value in translate_dic.items():\n                if translation_key in decoded_line:\n                    header_value = decoded_line.split(':')[-1]\n                    header[translation_value] = header_value[:-1]\n\n        all_header.append(header)\n        await reportStatusToJs("READING_HEADERS_FROM_SUB_BBL_COMPLETE", sub_bbl_index)\n\n    await reportStatusToJs("READING_HEADERS_COMPLETE")\n    return all_header\n\nasync def run():\n    """\n    Run the splitting and decoding process.\n\n    Args:\n        None\n\n    Returns:\n        None\n    """\n    bbl_path = "/log.bbl"\n    out_path = "/splits"\n    await reportStatusToJs("RUNNING")\n    sub_bbl_filenames = await split_bbl(bbl_path, out_path)\n    all_sub_bbl_headers = await get_log_header(sub_bbl_filenames)\n\n    combined_json_output = []\n    for header, index in all_sub_bbl_headers:\n        combined_json_output.append({\n            'header': header,\n            'bbl_filename': sub_bbl_filenames[index],\n        })\n\n    json_file_name = "/result.json"\n    with open(json_file_name, 'w', encoding='utf-8') as json_file:\n        json_file.write(json.dumps(combined_json_output, indent=4, sort_keys=True))\n    json_file.close()\n\n    await reportStatusToJs("COMPLETE")\n\nawait run() # noqa`.trim();
      break;
    }
    case PYTHON_ANALYZER_CODE_NAMES.ANALYZE_ONE_FLIGHT: {
      code = `from js_status import reportStatusToJs # noqa\nimport json\nimport numpy as np\nfrom pandas import read_csv\nfrom scipy.interpolate import interp1d\nfrom scipy.ndimage.filters import gaussian_filter1d\nfrom scipy.optimize import minimize\n\nclass Trace:\n    framelen = 1.           # length of each single frame over which to compute response\n    resplen = 0.5           # length of respose window\n    cutfreq = 25.           # cutfreqency of what is considered as input\n    tuk_alpha = 1.0         # alpha of tukey window, if used\n    superpos = 16           # sub windowing (superpos windows in framelen)\n    low_threshold = 50      # treshold for 'looooow input rate'\n    threshold = 500.        # threshold for 'high input rate'\n    noise_framelen = 0.3    # window width for noise analysis\n    noise_superpos = 16     # subsampling for noise analysis windows\n\n    def to_json_object(self):\n        output = {\n            'gyro': self.gyro.tolist(),\n            'input': self.input.tolist(),\n            'time': self.time.tolist(),\n            'throttle': self.throttle.tolist(),\n            'avr_t': self.avr_t.tolist(),\n            'spec_sm': self.spec_sm.tolist(),\n            'thr_response': {\n                'hist2d_norm': {\n                    'histogram': self.thr_response['hist2d_norm'][0].tolist(),\n                    'bins': self.thr_response['hist2d_norm'][1].tolist()\n                }\n            },\n            'time_resp': self.time_resp.tolist(),\n            'resp_low': [\n                self.resp_low[0].tolist(),\n            ],\n            'high_mask': self.high_mask.tolist(),\n            'noise_gyro': {\n                'throt_hist_avr': self.noise_gyro['throt_hist_avr'].tolist(),\n                'throt_axis': self.noise_gyro['throt_axis'].tolist(),\n                'freq_axis': self.noise_gyro['freq_axis'].tolist(),\n                'hist2d_norm': self.noise_gyro['hist2d_norm'].tolist(),\n                'hist2d_sm': self.noise_gyro['hist2d_sm'].tolist(),\n                'hist2d': self.noise_gyro['hist2d'].tolist(),\n                'max': self.noise_gyro['max']\n            },\n            'noise_d': {\n                'throt_hist_avr': self.noise_d['throt_hist_avr'].tolist(),\n                'throt_axis': self.noise_d['throt_axis'].tolist(),\n                'freq_axis': self.noise_d['freq_axis'].tolist(),\n                'hist2d_norm': self.noise_d['hist2d_norm'].tolist(),\n                'hist2d_sm': self.noise_d['hist2d_sm'].tolist(),\n                'hist2d': self.noise_d['hist2d'].tolist(),\n                'max': self.noise_d['max']\n            },\n            'noise_debug': {\n                'throt_hist_avr': self.noise_debug['throt_hist_avr'].tolist(),\n                'throt_axis': self.noise_debug['throt_axis'].tolist(),\n                'freq_axis': self.noise_debug['freq_axis'].tolist(),\n                'hist2d_norm': self.noise_debug['hist2d_norm'].tolist(),\n                'hist2d_sm': self.noise_debug['hist2d_sm'].tolist(),\n                'hist2d': self.noise_debug['hist2d'].tolist(),\n                'max': self.noise_debug['max']\n            },\n            'filter_trans': self.filter_trans.tolist(),\n        }\n\n        if self.high_mask.sum()>0:\n            output['resp_high'] = self.resp_high[0].tolist()\n\n        return output\n\n    def __init__(self, data):\n        self.data = data\n        self.input = self.equalize(data['time'], self.pid_in(data['p_err'], data['gyro'], data['P']))[1]  # /20.\n        self.data.update({'input': self.pid_in(data['p_err'], data['gyro'], data['P'])})\n        self.equalize_data()\n\n        self.time = self.data['time']\n        self.dt=self.time[0]-self.time[1]\n\n        self.input = self.data['input']\n\n        self.gyro = self.data['gyro']\n        self.throttle = self.data['throttle']\n        self.throt_hist, self.throt_scale = np.histogram(self.throttle, np.linspace(0, 100, 101, dtype=np.float64), density=True)\n\n        self.flen = self.stepcalc(self.time, Trace.framelen)        # array len corresponding to framelen in s\n        self.rlen = self.stepcalc(self.time, Trace.resplen)         # array len corresponding to resplen in s\n        self.time_resp = self.time[0:self.rlen]-self.time[0]\n\n        self.stacks = self.winstacker({'time':[],'input':[],'gyro':[], 'throttle':[]}, self.flen, Trace.superpos)                                  # [[time, input, output],]\n        self.window = np.hanning(self.flen)                                     #self.tukeywin(self.flen, self.tuk_alpha)\n        self.spec_sm, self.avr_t, self.avr_in, self.max_in, self.max_thr = self.stack_response(self.stacks, self.window)\n        self.low_mask, self.high_mask = self.low_high_mask(self.max_in, self.threshold)       #calcs masks for high and low inputs according to threshold\n        self.toolow_mask = self.low_high_mask(self.max_in, 20)[1]          #mask for ignoring noisy low input\n\n        self.resp_sm = self.weighted_mode_avr(self.spec_sm, self.toolow_mask, [-1.5,3.5], 1000)\n        self.resp_quality = -self.to_mask((np.abs(self.spec_sm -self.resp_sm[0]).mean(axis=1)).clip(0.5-1e-9,0.5))+1.\n        # masking by setting trottle of unwanted traces to neg\n        self.thr_response = self.hist2d(self.max_thr * (2. * (self.toolow_mask*self.resp_quality) - 1.), self.time_resp,\n                                        (self.spec_sm.transpose() * self.toolow_mask).transpose(), [101, self.rlen])\n\n        self.resp_low = self.weighted_mode_avr(self.spec_sm, self.low_mask*self.toolow_mask, [-1.5,3.5], 1000)\n        if self.high_mask.sum()>0:\n            self.resp_high = self.weighted_mode_avr(self.spec_sm, self.high_mask*self.toolow_mask, [-1.5,3.5], 1000)\n\n        self.noise_winlen = self.stepcalc(self.time, Trace.noise_framelen)\n        self.noise_stack = self.winstacker({'time':[], 'gyro':[], 'throttle':[], 'd_err':[], 'debug':[]},\n                                           self.noise_winlen, Trace.noise_superpos)\n        self.noise_win = np.hanning(self.noise_winlen)\n\n        self.noise_gyro = self.stackspectrum(self.noise_stack['time'],self.noise_stack['throttle'],self.noise_stack['gyro'], self.noise_win)\n        self.noise_d = self.stackspectrum(self.noise_stack['time'], self.noise_stack['throttle'], self.noise_stack['d_err'], self.noise_win)\n        self.noise_debug = self.stackspectrum(self.noise_stack['time'], self.noise_stack['throttle'], self.noise_stack['debug'], self.noise_win)\n        if self.noise_debug['hist2d'].sum()>0:\n            ## mask 0 entries\n            thr_mask = self.noise_gyro['throt_hist_avr'].clip(0,1)\n            self.filter_trans = np.average(self.noise_gyro['hist2d'], axis=1, weights=thr_mask)/\\n                                np.average(self.noise_debug['hist2d'], axis=1, weights=thr_mask)\n        else:\n            self.filter_trans = self.noise_gyro['hist2d'].mean(axis=1)*0.\n\n    @staticmethod\n    def low_high_mask(signal, threshold):\n        low = np.copy(signal)\n\n        low[low <=threshold] = 1.\n        low[low > threshold] = 0.\n        high = -low+1.\n\n        if high.sum() < 10:     # ignore high pinput that is too short\n            high *= 0.\n\n        return low, high\n\n    def to_mask(self, clipped):\n        clipped-=clipped.min()\n        clipped/=clipped.max()\n        return clipped\n\n    def pid_in(self, pval, gyro, pidp):\n        pidin = gyro + pval / (0.032029 * pidp)       # 0.032029 is P scaling factor from betaflight\n        return pidin\n\n    def rate_curve(self, rcin, inmax=500., outmax=800., rate=160.):\n        ### an estimated rate curve. not used.\n        expoin = (np.exp((rcin - inmax) / rate) - np.exp((-rcin - inmax) / rate)) * outmax\n        return expoin\n\n    def calc_delay(self, time, trace1, trace2):\n        ### minimizes trace1-trace2 by shifting trace1\n        tf1 = interp1d(time[2000:-2000], trace1[2000:-2000], fill_value=0., bounds_error=False)\n        tf2 = interp1d(time[2000:-2000], trace2[2000:-2000], fill_value=0., bounds_error=False)\n        fun = lambda x: ((tf1(time - x*0.5) - tf2(time+ x*0.5)) ** 2).mean()\n        shift = minimize(fun, np.array([0.01])).x[0]\n        steps = np.round(shift / (time[1] - time[0]))\n        return {'time':shift, 'steps':int(steps)}\n\n    def tukeywin(self, len, alpha=0.5):\n        ### makes tukey widow for envelopig\n        M = len\n        n = np.arange(M - 1.)  #\n        if alpha <= 0:\n            return np.ones(M)  # rectangular window\n        elif alpha >= 1:\n            return np.hanning(M)\n\n        # Normal case\n        x = np.linspace(0, 1, M, dtype=np.float64)\n        w = np.ones(x.shape)\n\n        # first condition 0 <= x < alpha/2\n        first_condition = x < alpha / 2\n        w[first_condition] = 0.5 * (1 + np.cos(2 * np.pi / alpha * (x[first_condition] - alpha / 2)))\n\n        # second condition already taken care of\n\n        # third condition 1 - alpha / 2 <= x <= 1\n        third_condition = x >= (1 - alpha / 2)\n        w[third_condition] = 0.5 * (1 + np.cos(2 * np.pi / alpha * (x[third_condition] - 1 + alpha / 2)))\n\n        return w\n\n    def equalize(self, time, data):\n        ### equalizes time scale\n        data_f = interp1d(time, data)\n        newtime = np.linspace(time[0], time[-1], len(time), dtype=np.float64)\n        return newtime, data_f(newtime)\n\n    def equalize_data(self):\n        ### equalizes full dict of data\n        time = self.data['time']\n        newtime = np.linspace(time[0], time[-1], len(time), dtype=np.float64)\n        for key in self.data:\n              if isinstance(self.data[key],np.ndarray):\n                  if len(self.data[key])==len(time):\n                      self.data[key]= interp1d(time, self.data[key])(newtime)\n        self.data['time']=newtime\n\n    def stepcalc(self, time, duration):\n        ### calculates frequency and resulting windowlength\n        tstep = (time[1]-time[0])\n        freq = 1./tstep\n        arr_len = duration * freq\n        return int(arr_len)\n\n    def winstacker(self, stackdict, flen, superpos):\n        ### makes stack of windows for deconvolution\n        tlen = len(self.data['time'])\n        shift = int(flen/superpos)\n        wins = int(tlen/shift)-superpos\n        for i in np.arange(wins):\n            for key in stackdict.keys():\n                stackdict[key].append(self.data[key][i * shift:i * shift + flen])\n        for k in stackdict.keys():\n            stackdict[k]=np.array(stackdict[k], dtype=np.float64)\n        return stackdict\n\n    def wiener_deconvolution(self, input, output, cutfreq):      # input/output are two-dimensional\n        pad = 1024 - (len(input[0]) % 1024)                     # padding to power of 2, increases transform speed\n        input = np.pad(input, [[0,0],[0,pad]], mode='constant')\n        output = np.pad(output, [[0, 0], [0, pad]], mode='constant')\n        H = np.fft.fft(input, axis=-1)\n        G = np.fft.fft(output,axis=-1)\n        freq = np.abs(np.fft.fftfreq(len(input[0]), self.dt))\n        sn = self.to_mask(np.clip(np.abs(freq), cutfreq-1e-9, cutfreq))\n        len_lpf=np.sum(np.ones_like(sn)-sn)\n        sn=self.to_mask(gaussian_filter1d(sn,len_lpf/6.))\n        sn= 10.*(-sn+1.+1e-9)       # +1e-9 to prohibit 0/0 situations\n        Hcon = np.conj(H)\n        deconvolved_sm = np.real(np.fft.ifft(G * Hcon / (H * Hcon + 1./sn),axis=-1))\n        return deconvolved_sm\n\n    def stack_response(self, stacks, window):\n        inp = stacks['input'] * window\n        outp = stacks['gyro'] * window\n        thr = stacks['throttle'] * window\n\n        deconvolved_sm = self.wiener_deconvolution(inp, outp, self.cutfreq)[:, :self.rlen]\n        delta_resp = deconvolved_sm.cumsum(axis=1)\n\n        max_thr = np.abs(np.abs(thr)).max(axis=1)\n        avr_in = np.abs(np.abs(inp)).mean(axis=1)\n        max_in = np.max(np.abs(inp), axis=1)\n        avr_t = stacks['time'].mean(axis=1)\n\n        return delta_resp, avr_t, avr_in, max_in, max_thr\n\n    def spectrum(self, time, traces):\n        ### fouriertransform for noise analysis. returns frequencies and spectrum.\n        pad = 1024 - (len(traces[0]) % 1024)  # padding to power of 2, increases transform speed\n        traces = np.pad(traces, [[0, 0], [0, pad]], mode='constant')\n        trspec = np.fft.rfft(traces, axis=-1, norm='ortho')\n        trfreq = np.fft.rfftfreq(len(traces[0]), time[1] - time[0])\n        return trfreq, trspec\n\n    def stackfilter(self, time, trace_ref, trace_filt, window):\n        ### calculates filter transmission and phaseshift from stack of windows. Not in use, maybe later.\n        # slicing off last 2s to get rid of landing\n        # maybe pass throttle for further analysis...\n        filt = trace_filt[:-int(Trace.noise_superpos * 2. / Trace.noise_framelen), :] * window\n        ref = trace_ref[:-int(Trace.noise_superpos * 2. / Trace.noise_framelen), :] * window\n        time = time[:-int(Trace.noise_superpos * 2. / Trace.noise_framelen), :]\n\n        full_freq_f, full_spec_f = self.spectrum(self.data['time'], [self.data['gyro']])\n        full_freq_r, full_spec_r = self.spectrum(self.data['time'], [self.data['debug']])\n\n        f_amp_freq, f_amp_hist = np.histogram(full_freq_f, weights=np.abs(full_spec_f.real).flatten(), bins=int(full_freq_f[-1]))\n        r_amp_freq, r_amp_hist = np.histogram(full_freq_r, weights=np.abs(full_spec_r.real).flatten(), bins=int(full_freq_r[-1]))\n\n    def hist2d(self, x, y, weights, bins):   #bins[nx,ny]\n        ### generates a 2d hist from input 1d axis for x,y. repeats them to match shape of weights X*Y (data points)\n        ### x will be 0-100%\n        freqs = np.repeat(np.array([y], dtype=np.float64), len(x), axis=0)\n        throts = np.repeat(np.array([x], dtype=np.float64), len(y), axis=0).transpose()\n        throt_hist_avr, throt_scale_avr = np.histogram(x, 101, [0, 100])\n\n        hist2d = np.histogram2d(throts.flatten(), freqs.flatten(),\n                                range=[[0, 100], [y[0], y[-1]]],\n                                bins=bins, weights=weights.flatten(), density=False)[0].transpose()\n\n        hist2d = np.array(abs(hist2d), dtype=np.float64)\n        hist2d_norm = np.copy(hist2d)\n        hist2d_norm /=  (throt_hist_avr + 1e-9)\n\n        return {\n            'hist2d_norm': hist2d_norm,\n            'hist2d': hist2d,\n            'throt_hist': throt_hist_avr,\n            'throt_scale': throt_scale_avr\n        }\n\n    def stackspectrum(self, time, throttle, trace, window):\n        ### calculates spectrogram from stack of windows against throttle.\n        # slicing off last 2s to get rid of landing\n        gyro = trace[:-int(Trace.noise_superpos*2./Trace.noise_framelen),:] * window\n        thr = throttle[:-int(Trace.noise_superpos*2./Trace.noise_framelen),:] * window\n        time = time[:-int(Trace.noise_superpos*2./Trace.noise_framelen),:]\n\n        freq, spec = self.spectrum(time[0], gyro)\n\n        weights = abs(spec.real)\n        avr_thr = np.abs(thr).max(axis=1)\n\n        hist2d=self.hist2d(avr_thr, freq,weights,[101,int(len(freq)/4)])\n\n        filt_width = 3  # width of gaussian smoothing for hist data\n        hist2d_sm = gaussian_filter1d(hist2d['hist2d_norm'], filt_width, axis=1, mode='constant')\n\n        # get max value in histogram >100hz\n        thresh = 100.\n        mask = self.to_mask(freq[:-1:4].clip(thresh-1e-9,thresh))\n        maxval = np.max(hist2d_sm.transpose()*mask)\n\n        return {\n            'throt_hist_avr': hist2d['throt_hist'],\n            'throt_axis': hist2d['throt_scale'],\n            'freq_axis': freq[::4],\n            'hist2d_norm': hist2d['hist2d_norm'],\n            'hist2d_sm': hist2d_sm,\n            'hist2d': hist2d['hist2d'],\n            'max':maxval\n        }\n\n    def weighted_mode_avr(self, values, weights, vertrange, vertbins):\n        ### finds the most common trace and std\n        threshold = 0.5  # threshold for std calculation\n        filt_width = 7  # width of gaussian smoothing for hist data\n\n        resp_y = np.linspace(vertrange[0], vertrange[-1], vertbins, dtype=np.float64)\n        times = np.repeat(np.array([self.time_resp],dtype=np.float64), len(values), axis=0)\n        weights = np.repeat(weights, len(values[0]))\n\n        hist2d = np.histogram2d(times.flatten(), values.flatten(),\n                                range=[[self.time_resp[0], self.time_resp[-1]], vertrange],\n                                bins=[len(times[0]), vertbins], weights=weights.flatten())[0].transpose()\n        ### shift outer edges by +-1e-5 (10us) bacause of dtype32. Otherwise different precisions lead to artefacting.\n        ### solution to this --> somethings strage here. In outer most edges some bins are doubled, some are empty.\n        ### Hence sometimes produces "divide by 0 error" in "/=" operation.\n\n        if hist2d.sum():\n            hist2d_sm = gaussian_filter1d(hist2d, filt_width, axis=0, mode='constant')\n            hist2d_sm /= np.max(hist2d_sm, 0)\n\n\n            pixelpos = np.repeat(resp_y.reshape(len(resp_y), 1), len(times[0]), axis=1)\n            avr = np.average(pixelpos, 0, weights=hist2d_sm * hist2d_sm)\n        else:\n            hist2d_sm = hist2d\n            avr = np.zeros_like(self.time_resp)\n        # only used for monochrome error width\n        hist2d[hist2d <= threshold] = 0.\n        hist2d[hist2d > threshold] = 0.5 / (vertbins / (vertrange[-1] - vertrange[0]))\n\n        std = np.sum(hist2d, 0)\n\n        return avr, std, [self.time_resp, resp_y, hist2d_sm]\n\n    ### calculates weighted avverage and resulting errors\n    def weighted_avg_and_std(self, values, weights):\n        average = np.average(values, axis=0, weights=weights)\n        variance = np.average((values - average) ** 2, axis=0, weights=weights)\n        return (average, np.sqrt(variance))\n\nclass CSV_log:\n    def __init__(self, fpath, headdict, result_path):\n        self.file = fpath\n        self.headdict = headdict\n        self.result_path = result_path\n\n    async def asyncInit(self):\n        await reportStatusToJs("READING_DECODED_SUB_BBL_START")\n        self.data = self.readcsv(self.file)\n        await reportStatusToJs("READING_DECODED_SUB_BBL_COMPLETE")\n\n        self.traces = self.find_traces(self.data)\n        await reportStatusToJs("RUNNING_PID_ANALYSIS_ON_SUB_BBL_START")\n        self.roll, self.pitch, self.yaw = self.__analyze()\n        await reportStatusToJs("RUNNING_PID_ANALYSIS_ON_SUB_BBL_COMPLETE")\n\n        await reportStatusToJs("SAVING_PID_ANALYSIS_RESULTS_FROM_SUB_BBL_START")\n        fpath = self.file\n        combined_json_output = {\n            'roll': self.roll.to_json_object(),\n            'pitch': self.pitch.to_json_object(),\n            'yaw': self.yaw.to_json_object(),\n            'headdict': self.headdict\n        }\n        with open(self.result_path, 'w', encoding='utf-8') as json_file:\n            json_file.write(json.dumps(combined_json_output, indent=4, sort_keys=True))\n        json_file.close()\n\n        await reportStatusToJs("SAVING_PID_ANALYSIS_RESULTS_FROM_SUB_BBL_COMPLETE")\n\n    def __analyze(self):\n        analyzed = []\n        for t in self.traces:\n            logging.info(t['name'] + '...   ')\n            analyzed.append(Trace(t))\n        return analyzed\n\n    def readcsv(self, fpath):\n        logging.info('Reading: Log '+str(self.headdict['logNum']))\n        datdic = {}\n        ### keycheck for 'usecols' only reads usefull traces, uncommend if needed\n        wanted =  ['time (us)',\n                   'rcCommand[0]', 'rcCommand[1]', 'rcCommand[2]', 'rcCommand[3]',\n                   'axisP[0]','axisP[1]','axisP[2]',\n                   'axisI[0]', 'axisI[1]', 'axisI[2]',\n                   'axisD[0]', 'axisD[1]','axisD[2]',\n                   'gyroADC[0]', 'gyroADC[1]', 'gyroADC[2]',\n                   'gyroData[0]', 'gyroData[1]', 'gyroData[2]',\n                   'ugyroADC[0]', 'ugyroADC[1]', 'ugyroADC[2]',\n                   #'accSmooth[0]','accSmooth[1]', 'accSmooth[2]',\n                   'debug[0]', 'debug[1]', 'debug[2]','debug[3]',\n                   #'motor[0]', 'motor[1]', 'motor[2]', 'motor[3]',\n                   #'energyCumulative (mAh)','vbatLatest (V)', 'amperageLatest (A)'\n                   ]\n        data = read_csv(fpath, header=0, skipinitialspace=1, usecols=lambda k: k in wanted, dtype=np.float64)\n        datdic.update({'time_us': data['time (us)'].values * 1e-6})\n        datdic.update({'throttle': data['rcCommand[3]'].values})\n\n        for i in ['0', '1', '2']:\n            datdic.update({'rcCommand' + i: data['rcCommand['+i+']'].values})\n            #datdic.update({'PID loop in' + i: data['axisP[' + i + ']'].values})\n            try:\n                datdic.update({'debug' + i: data['debug[' + i + ']'].values})\n            except:\n                logging.warning('No debug['+str(i)+'] trace found!')\n                datdic.update({'debug' + i: np.zeros_like(data['rcCommand[' + i + ']'].values)})\n\n            # get P trace (including case of missing trace)\n            try:\n                datdic.update({'PID loop in' + i: data['axisP[' + i + ']'].values})\n            except:\n                logging.warning('No P['+str(i)+'] trace found!')\n                datdic.update({'PID loop in' + i: np.zeros_like(data['rcCommand[' + i + ']'].values)})\n\n            try:\n                datdic.update({'d_err'+i: data['axisD[' + i+']'].values})\n            except:\n                logging.warning('No D['+str(i)+'] trace found!')\n                datdic.update({'d_err' + i: np.zeros_like(data['rcCommand[' + i + ']'].values)})\n\n            try:\n                datdic.update({'I_term'+i: data['axisI[' + i+']'].values})\n            except:\n                if i<2:\n                    logging.warning('No I['+str(i)+'] trace found!')\n                datdic.update({'I_term' + i: np.zeros_like(data['rcCommand[' + i + ']'].values)})\n\n            datdic.update({'PID sum' + i: datdic['PID loop in'+i]+datdic['I_term'+i]+datdic['d_err'+i]})\n            \n            if 'gyroADC[0]' in data.keys():\n                datdic.update({'gyroData' + i: data['gyroADC[' + i+']'].values})\n            elif 'gyroData[0]' in data.keys():\n                datdic.update({'gyroData' + i: data['gyroData[' + i+']'].values})\n            elif 'ugyroADC[0]' in data.keys():\n                datdic.update({'gyroData' + i: data['ugyroADC[' + i+']'].values})\n            else:\n                logging.warning('No gyro trace found!')\n        return datdic\n\n\n    def find_traces(self, dat):\n        time = self.data['time_us']\n        throttle = dat['throttle']\n\n        throt = ((throttle - 1000.) / (float(self.headdict['maxThrottle']) - 1000.)) * 100.\n\n        traces = [{'name':'roll'},{'name':'pitch'},{'name':'yaw'}]\n\n        for i, dic in enumerate(traces):\n            dic.update({'time':time})\n            dic.update({'p_err':dat['PID loop in'+str(i)]})\n            dic.update({'rcinput': dat['rcCommand' + str(i)]})\n            dic.update({'gyro':dat['gyroData'+str(i)]})\n            dic.update({'PIDsum':dat['PID sum'+str(i)]})\n            dic.update({'d_err': dat['d_err' + str(i)]})\n            dic.update({'debug': dat['debug' + str(i)]})\n            if 'KISS' in self.headdict['fwType']:\n                dic.update({'P': 1.})\n                self.headdict.update({'tpa_percent': 0.})\n            elif 'Raceflight' in self.headdict['fwType']:\n                dic.update({'P': 1.})\n                self.headdict.update({'tpa_percent': 0.})\n\n            else:\n                dic.update({'P':float((self.headdict[dic['name']+'PID']).split(',')[0])})\n                self.headdict.update({'tpa_percent': (float(self.headdict['tpa_breakpoint']) - 1000.) / 10.})\n\n            dic.update({'throttle':throt})\n\n        return traces\n\n\nasync def run():\n    log_csv_path = "/log.csv"\n    log_header_path = "/log-header.json"\n    result_path = "/result.json"\n\n    # read headdict from log_header.json\n    with open(log_header_path, 'r', encoding='utf-8') as header_file:\n        header_dict = json.load(header_file)\n    header_file.close()\n\n    log = CSV_log(log_csv_path, header_dict, result_path)\n    await log.asyncInit()\n\n    del log\n\nawait run() # noqa`.trim();
      break;
    }
    default: {
      throw new Error(`Unknown code-placeholder name: ${name}`);
    }
  }

  if (code === undefined || code.trim() === "") {
    code = (await fetch(`./${name}`).then((response) =>
      response.text()
    )) as string;
  }

  return code;
}
